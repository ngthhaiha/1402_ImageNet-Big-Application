{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce65057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:20:12.544335Z",
     "iopub.status.busy": "2026-01-30T11:20:12.544035Z",
     "iopub.status.idle": "2026-01-30T11:20:18.240783Z",
     "shell.execute_reply": "2026-01-30T11:20:18.240041Z"
    },
    "papermill": {
     "duration": 5.70373,
     "end_time": "2026-01-30T11:20:18.242273",
     "exception": false,
     "start_time": "2026-01-30T11:20:12.538543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/STG-NF'...\r\n",
      "remote: Enumerating objects: 449, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (449/449), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (88/88), done.\u001b[K\r\n",
      "remote: Total 449 (delta 284), reused 423 (delta 265), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (449/449), 827.77 KiB | 4.33 MiB/s, done.\r\n",
      "Resolving deltas: 100% (284/284), done.\r\n",
      "Cloning into '/kaggle/working/AlphaPose'...\r\n",
      "remote: Enumerating objects: 2749, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\r\n",
      "remote: Total 2749 (delta 4), reused 0 (delta 0), pack-reused 2740 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (2749/2749), 118.82 MiB | 39.53 MiB/s, done.\r\n",
      "Resolving deltas: 100% (1379/1379), done.\r\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Clone STG-NF và AlphaPose\n",
    "!git clone https://github.com/orhir/STG-NF.git /kaggle/working/STG-NF\n",
    "!git clone https://github.com/MVIG-SJTU/AlphaPose.git /kaggle/working/AlphaPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80e34c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:20:18.251768Z",
     "iopub.status.busy": "2026-01-30T11:20:18.251104Z",
     "iopub.status.idle": "2026-01-30T11:20:19.113042Z",
     "shell.execute_reply": "2026-01-30T11:20:19.112070Z"
    },
    "papermill": {
     "duration": 0.868064,
     "end_time": "2026-01-30T11:20:19.114536",
     "exception": false,
     "start_time": "2026-01-30T11:20:18.246472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/AlphaPose\n",
      "Cloning into 'PoseFlow'...\r\n",
      "remote: Enumerating objects: 165, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (55/55), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (45/45), done.\u001b[K\r\n",
      "remote: Total 165 (delta 33), reused 25 (delta 9), pack-reused 110 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (165/165), 9.52 MiB | 38.99 MiB/s, done.\r\n",
      "Resolving deltas: 100% (65/65), done.\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/AlphaPose\n",
    "!git clone https://github.com/YuliangXiu/PoseFlow.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a889e496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:20:19.123929Z",
     "iopub.status.busy": "2026-01-30T11:20:19.123637Z",
     "iopub.status.idle": "2026-01-30T11:26:09.727713Z",
     "shell.execute_reply": "2026-01-30T11:26:09.726581Z"
    },
    "papermill": {
     "duration": 350.610741,
     "end_time": "2026-01-30T11:26:09.729525",
     "exception": false,
     "start_time": "2026-01-30T11:20:19.118784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"numpy==1.26.4\"\n",
    "!pip install cython pyyaml yacs tqdm matplotlib cython-bbox\n",
    "!python setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba2d3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:26:09.739043Z",
     "iopub.status.busy": "2026-01-30T11:26:09.738760Z",
     "iopub.status.idle": "2026-01-30T11:26:09.813700Z",
     "shell.execute_reply": "2026-01-30T11:26:09.812745Z"
    },
    "papermill": {
     "duration": 0.08119,
     "end_time": "2026-01-30T11:26:09.814962",
     "exception": false,
     "start_time": "2026-01-30T11:26:09.733772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "list len: 1247\n",
      "first item keys: ['image_id', 'category_id', 'keypoints', 'score', 'box', 'idx']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "p=\"/kaggle/input/shanghai-alphapose/alphapose_out/train/01_001_alphapose_results.json\"\n",
    "d=json.load(open(p))\n",
    "print(type(d))\n",
    "if isinstance(d, dict):\n",
    "    print(\"dict keys:\", list(d.keys())[:30])\n",
    "elif isinstance(d, list):\n",
    "    print(\"list len:\", len(d))\n",
    "    print(\"first item keys:\", list(d[0].keys())[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd0058d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:26:09.824328Z",
     "iopub.status.busy": "2026-01-30T11:26:09.823815Z",
     "iopub.status.idle": "2026-01-30T11:26:18.701108Z",
     "shell.execute_reply": "2026-01-30T11:26:18.700236Z"
    },
    "papermill": {
     "duration": 8.88347,
     "end_time": "2026-01-30T11:26:18.702645",
     "exception": false,
     "start_time": "2026-01-30T11:26:09.819175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd /kaggle/working/AlphaPose\n",
    "\n",
    "!mkdir -p detector/yolo/data\n",
    "!wget -O detector/yolo/data/yolov3-spp.weights \"https://pjreddie.com/media/files/yolov3-spp.weights\"\n",
    "\n",
    "# Tạo thư mục chứa weights (nếu chưa có)\n",
    "!mkdir -p pretrained_models\n",
    "# Copy file .pth bạn đã upload vào Kaggle Input\n",
    "!cp /kaggle/input/pretrained-models/fast_421_res152_256x192.pth \\\n",
    "    pretrained_models/fast_421_res152_256x192.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aaca42",
   "metadata": {
    "papermill": {
     "duration": 0.00392,
     "end_time": "2026-01-30T11:26:18.710816",
     "exception": false,
     "start_time": "2026-01-30T11:26:18.706896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13df438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:26:18.719911Z",
     "iopub.status.busy": "2026-01-30T11:26:18.719631Z",
     "iopub.status.idle": "2026-01-30T11:27:43.653324Z",
     "shell.execute_reply": "2026-01-30T11:27:43.652430Z"
    },
    "papermill": {
     "duration": 84.939919,
     "end_time": "2026-01-30T11:27:43.654607",
     "exception": false,
     "start_time": "2026-01-30T11:26:18.714688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 330 videos.\n",
      "Tổng số batch: 4 (mỗi batch 100 video)\n",
      "Batch được chọn để chạy: [4]\n",
      "\n",
      "==============================\n",
      "      CHẠY BATCH 4/4\n",
      "      Số video: 30\n",
      "==============================\n",
      "\n",
      "=== Extracting: 11_003 ===\n",
      "Extracted 675 frames.\n",
      "Renaming frames...\n",
      "Done video 11_003.\n",
      "\n",
      "=== Extracting: 11_004 ===\n",
      "Extracted 250 frames.\n",
      "Renaming frames...\n",
      "Done video 11_004.\n",
      "\n",
      "=== Extracting: 11_005 ===\n",
      "Extracted 1100 frames.\n",
      "Renaming frames...\n",
      "Done video 11_005.\n",
      "\n",
      "=== Extracting: 11_006 ===\n",
      "Extracted 550 frames.\n",
      "Renaming frames...\n",
      "Done video 11_006.\n",
      "\n",
      "=== Extracting: 11_007 ===\n",
      "Extracted 475 frames.\n",
      "Renaming frames...\n",
      "Done video 11_007.\n",
      "\n",
      "=== Extracting: 11_008 ===\n",
      "Extracted 625 frames.\n",
      "Renaming frames...\n",
      "Done video 11_008.\n",
      "\n",
      "=== Extracting: 11_009 ===\n",
      "Extracted 1800 frames.\n",
      "Renaming frames...\n",
      "Done video 11_009.\n",
      "\n",
      "=== Extracting: 11_010 ===\n",
      "Extracted 525 frames.\n",
      "Renaming frames...\n",
      "Done video 11_010.\n",
      "\n",
      "=== Extracting: 12_001 ===\n",
      "Extracted 425 frames.\n",
      "Renaming frames...\n",
      "Done video 12_001.\n",
      "\n",
      "=== Extracting: 12_002 ===\n",
      "Extracted 750 frames.\n",
      "Renaming frames...\n",
      "Done video 12_002.\n",
      "\n",
      "=== Extracting: 12_003 ===\n",
      "Extracted 725 frames.\n",
      "Renaming frames...\n",
      "Done video 12_003.\n",
      "\n",
      "=== Extracting: 12_004 ===\n",
      "Extracted 1075 frames.\n",
      "Renaming frames...\n",
      "Done video 12_004.\n",
      "\n",
      "=== Extracting: 12_005 ===\n",
      "Extracted 1175 frames.\n",
      "Renaming frames...\n",
      "Done video 12_005.\n",
      "\n",
      "=== Extracting: 12_006 ===\n",
      "Extracted 875 frames.\n",
      "Renaming frames...\n",
      "Done video 12_006.\n",
      "\n",
      "=== Extracting: 12_007 ===\n",
      "Extracted 850 frames.\n",
      "Renaming frames...\n",
      "Done video 12_007.\n",
      "\n",
      "=== Extracting: 12_008 ===\n",
      "Extracted 725 frames.\n",
      "Renaming frames...\n",
      "Done video 12_008.\n",
      "\n",
      "=== Extracting: 12_009 ===\n",
      "Extracted 900 frames.\n",
      "Renaming frames...\n",
      "Done video 12_009.\n",
      "\n",
      "=== Extracting: 12_010 ===\n",
      "Extracted 1396 frames.\n",
      "Renaming frames...\n",
      "Done video 12_010.\n",
      "\n",
      "=== Extracting: 12_011 ===\n",
      "Extracted 1650 frames.\n",
      "Renaming frames...\n",
      "Done video 12_011.\n",
      "\n",
      "=== Extracting: 12_012 ===\n",
      "Extracted 625 frames.\n",
      "Renaming frames...\n",
      "Done video 12_012.\n",
      "\n",
      "=== Extracting: 12_013 ===\n",
      "Extracted 4169 frames.\n",
      "Renaming frames...\n",
      "Done video 12_013.\n",
      "\n",
      "=== Extracting: 12_014 ===\n",
      "Extracted 4119 frames.\n",
      "Renaming frames...\n",
      "Done video 12_014.\n",
      "\n",
      "=== Extracting: 12_015 ===\n",
      "Extracted 1050 frames.\n",
      "Renaming frames...\n",
      "Done video 12_015.\n",
      "\n",
      "=== Extracting: 13_001 ===\n",
      "Extracted 601 frames.\n",
      "Renaming frames...\n",
      "Done video 13_001.\n",
      "\n",
      "=== Extracting: 13_002 ===\n",
      "Extracted 649 frames.\n",
      "Renaming frames...\n",
      "Done video 13_002.\n",
      "\n",
      "=== Extracting: 13_003 ===\n",
      "Extracted 649 frames.\n",
      "Renaming frames...\n",
      "Done video 13_003.\n",
      "\n",
      "=== Extracting: 13_004 ===\n",
      "Extracted 937 frames.\n",
      "Renaming frames...\n",
      "Done video 13_004.\n",
      "\n",
      "=== Extracting: 13_005 ===\n",
      "Extracted 385 frames.\n",
      "Renaming frames...\n",
      "Done video 13_005.\n",
      "\n",
      "=== Extracting: 13_006 ===\n",
      "Extracted 457 frames.\n",
      "Renaming frames...\n",
      "Done video 13_006.\n",
      "\n",
      "=== Extracting: 13_007 ===\n",
      "Extracted 1105 frames.\n",
      "Renaming frames...\n",
      "Done video 13_007.\n",
      "\n",
      "=== DONE: tất cả batch yêu cầu đã chạy xong ===\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# =======================\n",
    "# CẤU HÌNH\n",
    "# =======================\n",
    "VIDEO_DIR = Path(\"/kaggle/input/shanghaitech/ShangHaiTech/training/videos\")\n",
    "OUT_ROOT  = Path(\"/kaggle/working/frames\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 100               # số video mỗi batch\n",
    "RUN_BATCH = [4]               # <<< CHỈ CHẠY BATCH NÀY (batch bắt đầu từ 1)\n",
    "# Ví dụ:\n",
    "# RUN_BATCH = [1]          → chỉ chạy batch 1\n",
    "# RUN_BATCH = [2, 4]       → chạy 2 batch\n",
    "# RUN_BATCH = list(range(1,6)) → chạy tất cả batch\n",
    "\n",
    "# =======================\n",
    "# LẤY TOÀN BỘ VIDEO\n",
    "# =======================\n",
    "videos = sorted([v for v in VIDEO_DIR.iterdir() if v.suffix.lower() in [\".mp4\", \".avi\", \".mov\"]])\n",
    "total_videos = len(videos)\n",
    "\n",
    "print(f\"Found {total_videos} videos.\")\n",
    "\n",
    "# =======================\n",
    "# CHIA THÀNH BATCH\n",
    "# =======================\n",
    "batches = [\n",
    "    videos[i:i+BATCH_SIZE]\n",
    "    for i in range(0, total_videos, BATCH_SIZE)\n",
    "]\n",
    "\n",
    "print(f\"Tổng số batch: {len(batches)} (mỗi batch {BATCH_SIZE} video)\")\n",
    "print(f\"Batch được chọn để chạy: {RUN_BATCH}\")\n",
    "\n",
    "# =======================\n",
    "# XỬ LÝ TỪNG BATCH\n",
    "# =======================\n",
    "for batch_idx, batch in enumerate(batches, start=1):\n",
    "\n",
    "    if batch_idx not in RUN_BATCH:\n",
    "        continue  # bỏ qua batch này\n",
    "\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"      CHẠY BATCH {batch_idx}/{len(batches)}\")\n",
    "    print(f\"      Số video: {len(batch)}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    for vid in batch:\n",
    "        vid_name = vid.stem\n",
    "        out_dir = OUT_ROOT / vid_name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"\\n=== Extracting: {vid_name} ===\")\n",
    "\n",
    "        cap = cv2.VideoCapture(str(vid))\n",
    "        frame_id = 0\n",
    "\n",
    "        # --- trích frame ---\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_path = out_dir / f\"{frame_id:06d}.jpg\"\n",
    "            cv2.imwrite(str(frame_path), frame)\n",
    "            frame_id += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Extracted {frame_id} frames.\")\n",
    "\n",
    "        # --- đổi tên về <id>.jpg ---\n",
    "        print(\"Renaming frames...\")\n",
    "        for img in sorted(out_dir.glob(\"*.jpg\")):\n",
    "            old = img.stem\n",
    "            if old.isdigit():\n",
    "                new = f\"{int(old)}.jpg\"\n",
    "                img.rename(img.with_name(new))\n",
    "\n",
    "        print(f\"Done video {vid_name}.\")\n",
    "\n",
    "print(\"\\n=== DONE: tất cả batch yêu cầu đã chạy xong ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42206661",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-30T11:27:43.666894Z",
     "iopub.status.busy": "2026-01-30T11:27:43.666633Z",
     "iopub.status.idle": "2026-01-30T11:27:52.899754Z",
     "shell.execute_reply": "2026-01-30T11:27:52.898717Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 9.241014,
     "end_time": "2026-01-30T11:27:52.901187",
     "exception": false,
     "start_time": "2026-01-30T11:27:43.660173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/munkres-1.1.4-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/timm-0.1.20-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m103.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for torchreid (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "alphapose 0.5.0+c60106d requires halpecocotools, which is not installed.\r\n",
      "alphapose 0.5.0+c60106d requires tensorboardx, which is not installed.\r\n",
      "alphapose 0.5.0+c60106d requires terminaltables, which is not installed.\r\n",
      "alphapose 0.5.0+c60106d requires visdom, which is not installed.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -q install torchreid opencv-python scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d31ace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:27:52.915213Z",
     "iopub.status.busy": "2026-01-30T11:27:52.914519Z",
     "iopub.status.idle": "2026-01-30T11:28:00.576019Z",
     "shell.execute_reply": "2026-01-30T11:28:00.575051Z"
    },
    "papermill": {
     "duration": 7.669773,
     "end_time": "2026-01-30T11:28:00.577415",
     "exception": false,
     "start_time": "2026-01-30T11:27:52.907642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/munkres-1.1.4-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/timm-0.1.20-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.13.0 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q uninstall -y tensorboard protobuf\n",
    "!pip -q install \"protobuf==3.20.3\" \"tensorboard==2.13.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b4af90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:28:00.591756Z",
     "iopub.status.busy": "2026-01-30T11:28:00.591515Z",
     "iopub.status.idle": "2026-01-30T11:49:20.615282Z",
     "shell.execute_reply": "2026-01-30T11:49:20.614560Z"
    },
    "papermill": {
     "duration": 1280.040206,
     "end_time": "2026-01-30T11:49:20.624225",
     "exception": false,
     "start_time": "2026-01-30T11:28:00.584019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchreid/reid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n",
      "2026-01-30 11:28:10.107255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769772490.285075      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769772490.333105      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1LaG1EJpHrxdAxKnSCJ_i0u-nbxSAeiFY\n",
      "To: /root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\n",
      "100%|██████████| 10.9M/10.9M [00:00<00:00, 85.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/root/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "Found alphapose json files: 329\n",
      "Running batch 3: files [300:329] (29 videos)\n",
      "\n",
      "=== 11_004_alphapose_results (frame_folder=11_004) ===\n",
      "frames_loaded: 145 | det: 149 | det_with_feat: 149\n",
      "tracks_total(before_filter): 3 | tracks_saved(after_filter): 1\n",
      "Saved: /kaggle/working/tracked_json/11_004_alphapose_tracked_person.json\n",
      "\n",
      "=== 11_005_alphapose_results (frame_folder=11_005) ===\n",
      "frames_loaded: 434 | det: 830 | det_with_feat: 830\n",
      "tracks_total(before_filter): 10 | tracks_saved(after_filter): 8\n",
      "Saved: /kaggle/working/tracked_json/11_005_alphapose_tracked_person.json\n",
      "\n",
      "=== 11_006_alphapose_results (frame_folder=11_006) ===\n",
      "frames_loaded: 467 | det: 874 | det_with_feat: 874\n",
      "tracks_total(before_filter): 5 | tracks_saved(after_filter): 5\n",
      "Saved: /kaggle/working/tracked_json/11_006_alphapose_tracked_person.json\n",
      "\n",
      "=== 11_007_alphapose_results (frame_folder=11_007) ===\n",
      "frames_loaded: 404 | det: 650 | det_with_feat: 650\n",
      "tracks_total(before_filter): 7 | tracks_saved(after_filter): 4\n",
      "Saved: /kaggle/working/tracked_json/11_007_alphapose_tracked_person.json\n",
      "\n",
      "=== 11_008_alphapose_results (frame_folder=11_008) ===\n",
      "frames_loaded: 364 | det: 484 | det_with_feat: 484\n",
      "tracks_total(before_filter): 7 | tracks_saved(after_filter): 4\n",
      "Saved: /kaggle/working/tracked_json/11_008_alphapose_tracked_person.json\n",
      "\n",
      "=== 11_009_alphapose_results (frame_folder=11_009) ===\n",
      "frames_loaded: 1617 | det: 6620 | det_with_feat: 6620\n",
      "tracks_total(before_filter): 49 | tracks_saved(after_filter): 41\n",
      "Saved: /kaggle/working/tracked_json/11_009_alphapose_tracked_person.json\n",
      "\n",
      "=== 11_010_alphapose_results (frame_folder=11_010) ===\n",
      "frames_loaded: 300 | det: 849 | det_with_feat: 849\n",
      "tracks_total(before_filter): 11 | tracks_saved(after_filter): 8\n",
      "Saved: /kaggle/working/tracked_json/11_010_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_001_alphapose_results (frame_folder=12_001) ===\n",
      "frames_loaded: 425 | det: 3291 | det_with_feat: 3291\n",
      "tracks_total(before_filter): 13 | tracks_saved(after_filter): 11\n",
      "Saved: /kaggle/working/tracked_json/12_001_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_002_alphapose_results (frame_folder=12_002) ===\n",
      "frames_loaded: 750 | det: 2553 | det_with_feat: 2553\n",
      "tracks_total(before_filter): 13 | tracks_saved(after_filter): 8\n",
      "Saved: /kaggle/working/tracked_json/12_002_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_003_alphapose_results (frame_folder=12_003) ===\n",
      "frames_loaded: 682 | det: 3096 | det_with_feat: 3096\n",
      "tracks_total(before_filter): 13 | tracks_saved(after_filter): 10\n",
      "Saved: /kaggle/working/tracked_json/12_003_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_004_alphapose_results (frame_folder=12_004) ===\n",
      "frames_loaded: 1056 | det: 2878 | det_with_feat: 2878\n",
      "tracks_total(before_filter): 17 | tracks_saved(after_filter): 13\n",
      "Saved: /kaggle/working/tracked_json/12_004_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_005_alphapose_results (frame_folder=12_005) ===\n",
      "frames_loaded: 1171 | det: 4842 | det_with_feat: 4842\n",
      "tracks_total(before_filter): 19 | tracks_saved(after_filter): 13\n",
      "Saved: /kaggle/working/tracked_json/12_005_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_006_alphapose_results (frame_folder=12_006) ===\n",
      "frames_loaded: 856 | det: 4017 | det_with_feat: 4017\n",
      "tracks_total(before_filter): 22 | tracks_saved(after_filter): 14\n",
      "Saved: /kaggle/working/tracked_json/12_006_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_007_alphapose_results (frame_folder=12_007) ===\n",
      "frames_loaded: 841 | det: 2062 | det_with_feat: 2062\n",
      "tracks_total(before_filter): 10 | tracks_saved(after_filter): 8\n",
      "Saved: /kaggle/working/tracked_json/12_007_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_008_alphapose_results (frame_folder=12_008) ===\n",
      "frames_loaded: 694 | det: 2183 | det_with_feat: 2183\n",
      "tracks_total(before_filter): 8 | tracks_saved(after_filter): 5\n",
      "Saved: /kaggle/working/tracked_json/12_008_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_009_alphapose_results (frame_folder=12_009) ===\n",
      "frames_loaded: 900 | det: 2356 | det_with_feat: 2356\n",
      "tracks_total(before_filter): 11 | tracks_saved(after_filter): 7\n",
      "Saved: /kaggle/working/tracked_json/12_009_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_010_alphapose_results (frame_folder=12_010) ===\n",
      "frames_loaded: 860 | det: 1968 | det_with_feat: 1968\n",
      "tracks_total(before_filter): 10 | tracks_saved(after_filter): 8\n",
      "Saved: /kaggle/working/tracked_json/12_010_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_011_alphapose_results (frame_folder=12_011) ===\n",
      "frames_loaded: 1615 | det: 5632 | det_with_feat: 5632\n",
      "tracks_total(before_filter): 33 | tracks_saved(after_filter): 22\n",
      "Saved: /kaggle/working/tracked_json/12_011_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_012_alphapose_results (frame_folder=12_012) ===\n",
      "frames_loaded: 589 | det: 1375 | det_with_feat: 1375\n",
      "tracks_total(before_filter): 9 | tracks_saved(after_filter): 6\n",
      "Saved: /kaggle/working/tracked_json/12_012_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_013_alphapose_results (frame_folder=12_013) ===\n",
      "frames_loaded: 2539 | det: 5470 | det_with_feat: 5470\n",
      "tracks_total(before_filter): 41 | tracks_saved(after_filter): 24\n",
      "Saved: /kaggle/working/tracked_json/12_013_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_014_alphapose_results (frame_folder=12_014) ===\n",
      "frames_loaded: 2497 | det: 5398 | det_with_feat: 5398\n",
      "tracks_total(before_filter): 34 | tracks_saved(after_filter): 23\n",
      "Saved: /kaggle/working/tracked_json/12_014_alphapose_tracked_person.json\n",
      "\n",
      "=== 12_015_alphapose_results (frame_folder=12_015) ===\n",
      "frames_loaded: 1050 | det: 2464 | det_with_feat: 2464\n",
      "tracks_total(before_filter): 12 | tracks_saved(after_filter): 9\n",
      "Saved: /kaggle/working/tracked_json/12_015_alphapose_tracked_person.json\n",
      "\n",
      "=== 13_001_alphapose_results (frame_folder=13_001) ===\n",
      "frames_loaded: 559 | det: 903 | det_with_feat: 903\n",
      "tracks_total(before_filter): 11 | tracks_saved(after_filter): 8\n",
      "Saved: /kaggle/working/tracked_json/13_001_alphapose_tracked_person.json\n",
      "\n",
      "=== 13_002_alphapose_results (frame_folder=13_002) ===\n",
      "frames_loaded: 605 | det: 1774 | det_with_feat: 1774\n",
      "tracks_total(before_filter): 15 | tracks_saved(after_filter): 11\n",
      "Saved: /kaggle/working/tracked_json/13_002_alphapose_tracked_person.json\n",
      "\n",
      "=== 13_003_alphapose_results (frame_folder=13_003) ===\n",
      "frames_loaded: 649 | det: 1802 | det_with_feat: 1802\n",
      "tracks_total(before_filter): 15 | tracks_saved(after_filter): 10\n",
      "Saved: /kaggle/working/tracked_json/13_003_alphapose_tracked_person.json\n",
      "\n",
      "=== 13_004_alphapose_results (frame_folder=13_004) ===\n",
      "frames_loaded: 906 | det: 2083 | det_with_feat: 2083\n",
      "tracks_total(before_filter): 17 | tracks_saved(after_filter): 12\n",
      "Saved: /kaggle/working/tracked_json/13_004_alphapose_tracked_person.json\n",
      "\n",
      "=== 13_005_alphapose_results (frame_folder=13_005) ===\n",
      "frames_loaded: 308 | det: 386 | det_with_feat: 386\n",
      "tracks_total(before_filter): 6 | tracks_saved(after_filter): 3\n",
      "Saved: /kaggle/working/tracked_json/13_005_alphapose_tracked_person.json\n",
      "\n",
      "=== 13_006_alphapose_results (frame_folder=13_006) ===\n",
      "frames_loaded: 457 | det: 798 | det_with_feat: 798\n",
      "tracks_total(before_filter): 8 | tracks_saved(after_filter): 7\n",
      "Saved: /kaggle/working/tracked_json/13_006_alphapose_tracked_person.json\n",
      "\n",
      "=== 13_007_alphapose_results (frame_folder=13_007) ===\n",
      "frames_loaded: 1086 | det: 2707 | det_with_feat: 2707\n",
      "tracks_total(before_filter): 20 | tracks_saved(after_filter): 15\n",
      "Saved: /kaggle/working/tracked_json/13_007_alphapose_tracked_person.json\n",
      "\n",
      "DONE. Output folder: /kaggle/working/tracked_json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Batch reID tracking for AlphaPose JSONs -> *_tracked_person.json\n",
    "# Fixes:\n",
    "#  - Map json filename like \"01_001_alphapose_results.json\" -> frame folder \"01_001\"\n",
    "#  - Batch processing: 50 videos per batch\n",
    "#  - Debug stats to diagnose 0 tracks\n",
    "# ============================================================\n",
    "\n",
    "import os, json, glob, cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchreid import models\n",
    "\n",
    "# ----------------------------\n",
    "# USER CONFIG\n",
    "# ----------------------------\n",
    "ALPHAPOSE_DIR = \"/kaggle/input/shanghai-alphapose/alphapose_out/train\"\n",
    "FRAME_ROOT    = \"/kaggle/working/frames\"\n",
    "OUT_DIR       = \"/kaggle/working/tracked_json\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Batch\n",
    "BATCH_SIZE = 100\n",
    "BATCH_INDEX = 3  # 0 = first 50, 1 = next 50, ...\n",
    "\n",
    "# Tracking params\n",
    "COS_THR   = 0.30\n",
    "IOU_THR   = 0.05\n",
    "ALPHA     = 0.85\n",
    "MAX_MISS  = 30\n",
    "MIN_HITS  = 2\n",
    "EMA       = 0.90\n",
    "\n",
    "# Export filters\n",
    "MIN_TRACK_LEN = 24     # paper T=24; set 1 to debug quickly if still 0\n",
    "REQUIRE_CONFIRMED = True\n",
    "\n",
    "# ----------------------------\n",
    "# ReID model\n",
    "# ----------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "reid_model = models.build_model(name=\"osnet_x1_0\", num_classes=1000, pretrained=True).to(device).eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256, 128)),  # H,W\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "@torch.inference_mode()\n",
    "def extract_feat(img_bgr, box_xywh):\n",
    "    x, y, w, h = map(float, box_xywh)\n",
    "    x2, y2 = x + w, y + h\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    x1, y1 = max(0, int(x)),  max(0, int(y))\n",
    "    x2, y2 = min(W-1, int(x2)), min(H-1, int(y2))\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    crop = img_bgr[y1:y2, x1:x2]\n",
    "    if crop.size == 0:\n",
    "        return None\n",
    "    crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "    x = preprocess(crop_rgb).unsqueeze(0).to(device)\n",
    "    feat = reid_model(x)\n",
    "    feat = torch.nn.functional.normalize(feat, dim=1)\n",
    "    return feat.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "def bbox_xywh_to_xyxy(b):\n",
    "    x,y,w,h = map(float, b)\n",
    "    return [x, y, x+w, y+h]\n",
    "\n",
    "def iou_xyxy(a, b):\n",
    "    ax1,ay1,ax2,ay2 = a\n",
    "    bx1,by1,bx2,by2 = b\n",
    "    ix1,iy1 = max(ax1,bx1), max(ay1,by1)\n",
    "    ix2,iy2 = min(ax2,bx2), min(ay2,by2)\n",
    "    iw,ih = max(0, ix2-ix1), max(0, iy2-iy1)\n",
    "    inter = iw*ih\n",
    "    area_a = max(0,ax2-ax1)*max(0,ay2-ay1)\n",
    "    area_b = max(0,bx2-bx1)*max(0,by2-by1)\n",
    "    return inter / (area_a + area_b - inter + 1e-6)\n",
    "\n",
    "def cos_dist(f1, f2):\n",
    "    return 1.0 - float(np.dot(f1, f2))\n",
    "\n",
    "def parse_frame_id_from_image_id(image_id):\n",
    "    s = str(image_id)\n",
    "    if \"/\" in s:\n",
    "        _, fname = s.split(\"/\", 1)\n",
    "        return os.path.splitext(fname)[0]\n",
    "    base = os.path.splitext(s)[0]\n",
    "    # if ends with _000123 -> take last\n",
    "    if \"_\" in base:\n",
    "        return base.split(\"_\")[-1]\n",
    "    return base\n",
    "\n",
    "def load_frame(frame_folder_name, frame_id):\n",
    "    folder = os.path.join(FRAME_ROOT, frame_folder_name)\n",
    "    for ext in [\".jpg\", \".png\", \".jpeg\"]:\n",
    "        p = os.path.join(folder, f\"{frame_id}{ext}\")\n",
    "        if os.path.exists(p):\n",
    "            img = cv2.imread(p)\n",
    "            if img is not None:\n",
    "                return img\n",
    "    return None\n",
    "\n",
    "class Track:\n",
    "    def __init__(self, tid):\n",
    "        self.id = tid\n",
    "        self.feat = None\n",
    "        self.bbox_xyxy = None\n",
    "        self.miss = 0\n",
    "        self.hits = 0\n",
    "        self.confirmed = False\n",
    "        self.frames = {}  # frame_id -> {\"keypoints\": [...], \"scores\": float}\n",
    "\n",
    "def hungarian_match(tracks, dets):\n",
    "    if len(tracks) == 0 or len(dets) == 0:\n",
    "        return [], list(range(len(tracks))), list(range(len(dets)))\n",
    "\n",
    "    C = np.full((len(tracks), len(dets)), 1e6, dtype=np.float32)\n",
    "\n",
    "    for i, tr in enumerate(tracks):\n",
    "        for j, dt in enumerate(dets):\n",
    "            if tr.feat is None or dt[\"feat\"] is None:\n",
    "                continue\n",
    "            d_app = cos_dist(tr.feat, dt[\"feat\"])\n",
    "            iou = iou_xyxy(tr.bbox_xyxy, dt[\"bbox_xyxy\"])\n",
    "            if d_app > COS_THR and iou < IOU_THR:\n",
    "                continue\n",
    "            d_iou = 1.0 - iou\n",
    "            C[i, j] = ALPHA * d_app + (1.0 - ALPHA) * d_iou\n",
    "\n",
    "    r, c = linear_sum_assignment(C)\n",
    "    matches, used_t, used_d = [], set(), set()\n",
    "\n",
    "    for rr, cc in zip(r, c):\n",
    "        if C[rr, cc] >= 1e5:\n",
    "            continue\n",
    "        matches.append((rr, cc))\n",
    "        used_t.add(rr)\n",
    "        used_d.add(cc)\n",
    "\n",
    "    un_t = [i for i in range(len(tracks)) if i not in used_t]\n",
    "    un_d = [j for j in range(len(dets)) if j not in used_d]\n",
    "    return matches, un_t, un_d\n",
    "\n",
    "def safe_sort_frame_ids(frame_ids):\n",
    "    try:\n",
    "        return sorted(frame_ids, key=lambda x: int(str(x)))\n",
    "    except Exception:\n",
    "        return sorted(frame_ids, key=lambda x: str(x))\n",
    "\n",
    "def frame_folder_from_json_name(video_name):\n",
    "    # \"01_001_alphapose_results\" -> \"01_001\"\n",
    "    if video_name.endswith(\"_alphapose_results\"):\n",
    "        return video_name.replace(\"_alphapose_results\", \"\")\n",
    "    return video_name\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN\n",
    "# ----------------------------\n",
    "json_files_all = sorted(glob.glob(os.path.join(ALPHAPOSE_DIR, \"*.json\")))\n",
    "print(\"Found alphapose json files:\", len(json_files_all))\n",
    "\n",
    "start = BATCH_INDEX * BATCH_SIZE\n",
    "end = min(len(json_files_all), start + BATCH_SIZE)\n",
    "json_files = json_files_all[start:end]\n",
    "print(f\"Running batch {BATCH_INDEX}: files [{start}:{end}] ({len(json_files)} videos)\")\n",
    "\n",
    "global_next_tid = 1\n",
    "\n",
    "for json_path in json_files:\n",
    "    video_name = os.path.splitext(os.path.basename(json_path))[0]\n",
    "    frame_folder = frame_folder_from_json_name(video_name)\n",
    "\n",
    "    frame_dir = os.path.join(FRAME_ROOT, frame_folder)\n",
    "    if not os.path.isdir(frame_dir):\n",
    "        print(f\"\\n=== {video_name} ===\")\n",
    "        print(\"SKIP: frame folder not found:\", frame_dir)\n",
    "        continue\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        det_list = json.load(f)\n",
    "\n",
    "    by_frame = defaultdict(list)\n",
    "    for det in det_list:\n",
    "        frame_id = parse_frame_id_from_image_id(det.get(\"image_id\"))\n",
    "        by_frame[str(frame_id)].append(det)\n",
    "\n",
    "    frame_ids = safe_sort_frame_ids(list(by_frame.keys()))\n",
    "    if len(frame_ids) == 0:\n",
    "        print(f\"\\n=== {video_name} ===\")\n",
    "        print(\"SKIP: no frames in json\")\n",
    "        continue\n",
    "\n",
    "    active, finished = [], []\n",
    "\n",
    "    frames_loaded = 0\n",
    "    det_count = 0\n",
    "    det_with_feat = 0\n",
    "\n",
    "    for frame_id in frame_ids:\n",
    "        img = load_frame(frame_folder, frame_id)\n",
    "        if img is None:\n",
    "            for tr in active:\n",
    "                tr.miss += 1\n",
    "            continue\n",
    "\n",
    "        frames_loaded += 1\n",
    "        dets_raw = by_frame[frame_id]\n",
    "\n",
    "        dets = []\n",
    "        for d in dets_raw:\n",
    "            box = d.get(\"box\", None)\n",
    "            kps = d.get(\"keypoints\", None)\n",
    "            sc  = float(d.get(\"score\", 0.0) or 0.0)\n",
    "            if box is None or kps is None:\n",
    "                continue\n",
    "\n",
    "            det_count += 1\n",
    "            feat = extract_feat(img, box)\n",
    "            if feat is not None:\n",
    "                det_with_feat += 1\n",
    "\n",
    "            dets.append({\n",
    "                \"bbox_xyxy\": bbox_xywh_to_xyxy(box),\n",
    "                \"feat\": feat,\n",
    "                \"keypoints\": kps,\n",
    "                \"score\": sc\n",
    "            })\n",
    "\n",
    "        if len(active) == 0:\n",
    "            for dt in dets:\n",
    "                tr = Track(global_next_tid); global_next_tid += 1\n",
    "                tr.bbox_xyxy = dt[\"bbox_xyxy\"]\n",
    "                tr.feat = dt[\"feat\"]\n",
    "                tr.hits = 1\n",
    "                tr.confirmed = (tr.hits >= MIN_HITS)\n",
    "                tr.frames[str(frame_id)] = {\"keypoints\": dt[\"keypoints\"], \"scores\": dt[\"score\"]}\n",
    "                active.append(tr)\n",
    "            continue\n",
    "\n",
    "        matches, un_t, un_d = hungarian_match(active, dets)\n",
    "\n",
    "        for ti, dj in matches:\n",
    "            tr = active[ti]\n",
    "            dt = dets[dj]\n",
    "            tr.bbox_xyxy = dt[\"bbox_xyxy\"]\n",
    "            if tr.feat is None:\n",
    "                tr.feat = dt[\"feat\"]\n",
    "            elif dt[\"feat\"] is not None:\n",
    "                tr.feat = EMA * tr.feat + (1.0 - EMA) * dt[\"feat\"]\n",
    "                tr.feat = tr.feat / (np.linalg.norm(tr.feat) + 1e-12)\n",
    "            tr.miss = 0\n",
    "            tr.hits += 1\n",
    "            tr.confirmed = tr.confirmed or (tr.hits >= MIN_HITS)\n",
    "            tr.frames[str(frame_id)] = {\"keypoints\": dt[\"keypoints\"], \"scores\": dt[\"score\"]}\n",
    "\n",
    "        for ti in un_t:\n",
    "            active[ti].miss += 1\n",
    "\n",
    "        for dj in un_d:\n",
    "            dt = dets[dj]\n",
    "            tr = Track(global_next_tid); global_next_tid += 1\n",
    "            tr.bbox_xyxy = dt[\"bbox_xyxy\"]\n",
    "            tr.feat = dt[\"feat\"]\n",
    "            tr.hits = 1\n",
    "            tr.confirmed = (tr.hits >= MIN_HITS)\n",
    "            tr.frames[str(frame_id)] = {\"keypoints\": dt[\"keypoints\"], \"scores\": dt[\"score\"]}\n",
    "            active.append(tr)\n",
    "\n",
    "        still = []\n",
    "        for tr in active:\n",
    "            if tr.miss > MAX_MISS:\n",
    "                finished.append(tr)\n",
    "            else:\n",
    "                still.append(tr)\n",
    "        active = still\n",
    "\n",
    "    finished.extend(active)\n",
    "\n",
    "    # Export\n",
    "    out_all = {}\n",
    "    out = {}\n",
    "    for tr in finished:\n",
    "        out_all[str(tr.id)] = tr.frames\n",
    "        if REQUIRE_CONFIRMED and (not tr.confirmed):\n",
    "            continue\n",
    "        if len(tr.frames) < MIN_TRACK_LEN:\n",
    "            continue\n",
    "        out[str(tr.id)] = tr.frames\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR, f\"{frame_folder}_alphapose_tracked_person.json\")\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(out, f)\n",
    "\n",
    "    print(f\"\\n=== {video_name} (frame_folder={frame_folder}) ===\")\n",
    "    print(\"frames_loaded:\", frames_loaded, \"| det:\", det_count, \"| det_with_feat:\", det_with_feat)\n",
    "    print(\"tracks_total(before_filter):\", len(out_all), \"| tracks_saved(after_filter):\", len(out))\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "print(\"\\nDONE. Output folder:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b7c2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T11:49:20.640877Z",
     "iopub.status.busy": "2026-01-30T11:49:20.640307Z",
     "iopub.status.idle": "2026-01-30T11:49:25.429699Z",
     "shell.execute_reply": "2026-01-30T11:49:25.428964Z"
    },
    "papermill": {
     "duration": 4.799076,
     "end_time": "2026-01-30T11:49:25.430883",
     "exception": false,
     "start_time": "2026-01-30T11:49:20.631807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file: /kaggle/working/tracked_json.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "input_dir = \"/kaggle/working/tracked_json\"\n",
    "output_zip = \"/kaggle/working/tracked_json\"\n",
    "\n",
    "shutil.make_archive(output_zip, 'zip', input_dir)\n",
    "\n",
    "print(\"Đã tạo file:\", output_zip + \".zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43f215",
   "metadata": {
    "papermill": {
     "duration": 0.007516,
     "end_time": "2026-01-30T11:49:25.446614",
     "exception": false,
     "start_time": "2026-01-30T11:49:25.439098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8292123,
     "sourceId": 13091244,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8517977,
     "sourceId": 13420771,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8800216,
     "sourceId": 13819016,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8929147,
     "sourceId": 14016243,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9219111,
     "sourceId": 14470777,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9229517,
     "sourceId": 14508410,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1759.682265,
   "end_time": "2026-01-30T11:49:28.544316",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-30T11:20:08.862051",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
